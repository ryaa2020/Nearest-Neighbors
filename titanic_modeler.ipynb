{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# hw4pr3titanic:  titanic-passenger clasification via nearest neighbors\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# SUGGESTION:  \n",
    "# \n",
    "# +++ copy-paste-and-alter from the iris- + births + digits-cleaning notebooks into here +++\n",
    "#\n",
    "# Here, there can be value in weighting columns with different coefficients... explore!\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries!\n",
    "import numpy as np      # numpy is Python's \"array\" library\n",
    "import pandas as pd     # Pandas is Python's \"data\" library (\"dataframe\" == spreadsheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titanic_cleaned.csv : file read into a pandas dataframe.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>45.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  sex      age  sibsp  parch  survived\n",
       "0          1    1  29.0000      0      0         1\n",
       "1          1    0   0.9167      1      2         1\n",
       "2          1    1   2.0000      1      2         0\n",
       "3          1    0  30.0000      1      2         0\n",
       "4          1    1  25.0000      1      2         0\n",
       "...      ...  ...      ...    ...    ...       ...\n",
       "1259       3    0  45.5000      0      0         0\n",
       "1262       3    1  14.5000      1      0         0\n",
       "1264       3    0  26.5000      0      0         0\n",
       "1265       3    0  27.0000      0      0         0\n",
       "1266       3    0  29.0000      0      0         0\n",
       "\n",
       "[1004 rows x 6 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's read in our flower data...\n",
    "# \n",
    "# for read_csv, use header=0 when row 0 is a header row\n",
    "# \n",
    "cleaned_filename = \"titanic_cleaned.csv\"\n",
    "df_tidy = pd.read_csv(cleaned_filename)   # encoding=\"utf-8\" et al.\n",
    "print(f\"{cleaned_filename} : file read into a pandas dataframe.\")\n",
    "df_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1004 entries, 0 to 1266\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pclass    1004 non-null   int64  \n",
      " 1   sex       1004 non-null   int64  \n",
      " 2   age       1004 non-null   float64\n",
      " 3   sibsp     1004 non-null   int64  \n",
      " 4   parch     1004 non-null   int64  \n",
      " 5   survived  1004 non-null   int64  \n",
      "dtypes: float64(1), int64(5)\n",
      "memory usage: 54.9 KB\n"
     ]
    }
   ],
   "source": [
    "df_tidy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>45.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  sex      age  sibsp  parch  survived\n",
       "0          1    1  29.0000      0      0         1\n",
       "1          1    0   0.9167      1      2         1\n",
       "2          1    1   2.0000      1      2         0\n",
       "3          1    0  30.0000      1      2         0\n",
       "4          1    1  25.0000      1      2         0\n",
       "...      ...  ...      ...    ...    ...       ...\n",
       "1259       3    0  45.5000      0      0         0\n",
       "1262       3    1  14.5000      1      0         0\n",
       "1264       3    0  26.5000      0      0         0\n",
       "1265       3    0  27.0000      0      0         0\n",
       "1266       3    0  29.0000      0      0         0\n",
       "\n",
       "[1004 rows x 6 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All of the columns need to be numeric, we'll drop irisname\n",
    "ROW = 0\n",
    "COLUMN = 1\n",
    "df_model1 = df_tidy\n",
    "df_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS is Index(['pclass', 'sex', 'age', 'sibsp', 'parch', 'survived'], dtype='object')\n",
      "\n",
      "COLUMNS[0] is pclass\n",
      "\n",
      "COL_INDEX is {'pclass': 0, 'sex': 1, 'age': 2, 'sibsp': 3, 'parch': 4, 'survived': 5}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "COLUMNS = df_model1.columns            # \"list\" of columns\n",
    "print(f\"COLUMNS is {COLUMNS}\\n\")  \n",
    "  # It's a \"pandas\" list, called an Index\n",
    "  # use it just as a Python list of strings:\n",
    "print(f\"COLUMNS[0] is {COLUMNS[0]}\\n\")\n",
    "\n",
    "# let's create a dictionary to look up any column index by name\n",
    "COL_INDEX = {}\n",
    "for i, name in enumerate(COLUMNS):\n",
    "    COL_INDEX[name] = i  # using the name (as key), look up the value (i)\n",
    "print(f\"COL_INDEX is {COL_INDEX}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "female maps to 0\n",
      "male maps to 1\n"
     ]
    }
   ],
   "source": [
    "S = ['female', 'male']   # int to str\n",
    "S_INDEX = {'female' : 0, 'male' : 1 }  # str to int\n",
    "\n",
    "def convert_s(sex):\n",
    "    \"\"\" return the sex index (a unique integer/category) \"\"\"\n",
    "    #print(f\"converting {speciesname}...\")\n",
    "    return S_INDEX[sex]\n",
    "\n",
    "# Let's try it out...\n",
    "for sex in S:\n",
    "    print(f\"{sex} maps to {convert_s(sex)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perished maps to 0\n",
      "survived maps to 1\n"
     ]
    }
   ],
   "source": [
    "# all of scikit-learn's ML routines need numbers, not strings\n",
    "#   ... even for categories/classifications (like species!)\n",
    "#   so, we will convert the flower-species to numbers\n",
    "\n",
    "OUTCOME = ['perished', 'survived']   # int to str\n",
    "OUTCOME_INDEX = {'perished':0, 'survived' :1}  # str to int\n",
    "\n",
    "def convert_outcome(outcome):\n",
    "    \"\"\" return the outcome index (1 - survived, 0 - perished) \"\"\"\n",
    "    #print(f\"converting {speciesname}...\")\n",
    "    return OUTCOME_INDEX[outcome]\n",
    "\n",
    "# Let's try it out...\n",
    "for state in OUTCOME:\n",
    "    print(f\"{state} maps to {convert_outcome(state)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yk/v4q7xgf968jgjzrckxn2cqx40000gn/T/ipykernel_1500/3604656441.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_model2['pclass'][df_model2['pclass'] == 3] *= 3\n",
      "/var/folders/yk/v4q7xgf968jgjzrckxn2cqx40000gn/T/ipykernel_1500/3604656441.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_model2['pclass'][df_model2['pclass'] == 2] *= 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>45.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  sex      age  sibsp  parch  survived\n",
       "0          1    1  29.0000      0      0         1\n",
       "1          1    0   0.9167      1      2         1\n",
       "2          1    1   2.0000      1      2         0\n",
       "3          1    0  30.0000      1      2         0\n",
       "4          1    1  25.0000      1      2         0\n",
       "...      ...  ...      ...    ...    ...       ...\n",
       "1259       9    0  45.5000      0      0         0\n",
       "1262       9    1  14.5000      1      0         0\n",
       "1264       9    0  26.5000      0      0         0\n",
       "1265       9    0  27.0000      0      0         0\n",
       "1266       9    0  29.0000      0      0         0\n",
       "\n",
       "[1004 rows x 6 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reweighting the classes\n",
    "df_model2 = df_model1.copy()\n",
    "df_model2['pclass'][df_model2['pclass'] == 3] *= 3\n",
    "df_model2['pclass'][df_model2['pclass'] == 2] *= 2\n",
    "df_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>45.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  sex      age  sibsp  parch  survived\n",
       "0          1    5  29.0000      0      0         1\n",
       "1          1    0   0.9167      1      2         1\n",
       "2          1    5   2.0000      1      2         0\n",
       "3          1    0  30.0000      1      2         0\n",
       "4          1    5  25.0000      1      2         0\n",
       "...      ...  ...      ...    ...    ...       ...\n",
       "1259       9    0  45.5000      0      0         0\n",
       "1262       9    5  14.5000      1      0         0\n",
       "1264       9    0  26.5000      0      0         0\n",
       "1265       9    0  27.0000      0      0         0\n",
       "1266       9    0  29.0000      0      0         0\n",
       "\n",
       "[1004 rows x 6 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reweighting the sex\n",
    "df_model3 = df_model2.copy()\n",
    "df_model3['sex'] *= 5\n",
    "df_model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yk/v4q7xgf968jgjzrckxn2cqx40000gn/T/ipykernel_1500/684199604.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_model4['parch'][df_model4['sex'] == 5] *= 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>25.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>45.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>14.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pclass  sex      age  sibsp  parch  survived\n",
       "0          1    5  29.0000      0      0         1\n",
       "1          1    0   0.9167      1      2         1\n",
       "2          1    5   2.0000      1      6         0\n",
       "3          1    0  30.0000      1      2         0\n",
       "4          1    5  25.0000      1      6         0\n",
       "...      ...  ...      ...    ...    ...       ...\n",
       "1259       9    0  45.5000      0      0         0\n",
       "1262       9    5  14.5000      1      0         0\n",
       "1264       9    0  26.5000      0      0         0\n",
       "1265       9    0  27.0000      0      0         0\n",
       "1266       9    0  29.0000      0      0         0\n",
       "\n",
       "[1004 rows x 6 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reweighting mothers with children or children with parents\n",
    "df_model4 = df_model3.copy()\n",
    "df_model4['parch'][df_model4['sex'] == 5] *= 3\n",
    "df_model4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.      5.     29.      0.      0.      1.    ]\n",
      " [ 1.      0.      0.9167  1.      2.      1.    ]\n",
      " [ 1.      5.      2.      1.      6.      0.    ]\n",
      " ...\n",
      " [ 9.      0.     26.5     0.      0.      0.    ]\n",
      " [ 9.      0.     27.      0.      0.      0.    ]\n",
      " [ 9.      0.     29.      0.      0.      0.    ]]\n"
     ]
    }
   ],
   "source": [
    "# converting types\n",
    "A = df_model4.to_numpy()    # .values gets the numpy array\n",
    "A = A.astype('float64')  # so many types:  www.tutorialspoint.com/numpy/numpy_data_types.htm\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The dataset has 1004 rows and 6 cols\n"
     ]
    }
   ],
   "source": [
    "NUM_ROWS, NUM_COLS = A.shape\n",
    "print(f\"\\nThe dataset has {NUM_ROWS} rows and {NUM_COLS} cols\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survivor #42 is [ 1.  5. 53.  0.  0.  1.]\n",
      "  Its pclass is 1.0\n",
      "  Its sex is 5.0\n",
      "  Its age is 53.0\n",
      "  Its sibsp is 0.0\n",
      "  Its parch is 0.0\n",
      "  Its survived is 1.0\n",
      " They survived\n",
      " They are male \n"
     ]
    }
   ],
   "source": [
    "# let's use all of our variables, to reinforce that we have\n",
    "# (1) names...\n",
    "# (2) access and control...\n",
    "\n",
    "# choose a row index, n:\n",
    "n = 42\n",
    "print(f\"survivor #{n} is {A[n]}\")\n",
    "S_INDEX = { 0 : 'female',  5 :'male'} \n",
    "\n",
    "for i in range(len(COLUMNS)):\n",
    "    colname = COLUMNS[i]\n",
    "    value = A[n][i]\n",
    "    print(f\"  Its {colname} is {value}\")\n",
    "\n",
    "# for sex\n",
    "se_index = COL_INDEX['survived']\n",
    "se_num = int(round(A[n][se_index]))\n",
    "outcome = OUTCOME[se_num]\n",
    "print(f\" They {outcome}\")\n",
    "\n",
    "# for survived\n",
    "sur_index = COL_INDEX['sex']\n",
    "sur_num = int(round(A[n][sur_index]))\n",
    "sex = S_INDEX[sur_num]\n",
    "print(f\" They are {sex} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Start of data definitions +++\n",
      "\n",
      "y_all (just the labels/species)   are \n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      "X_all (just the features) are \n",
      " [[ 1.      5.     29.      0.      0.    ]\n",
      " [ 1.      0.      0.9167  1.      2.    ]\n",
      " [ 1.      5.      2.      1.      6.    ]\n",
      " ...\n",
      " [ 9.      0.     26.5     0.      0.    ]\n",
      " [ 9.      0.     27.      0.      0.    ]\n",
      " [ 9.      0.     29.      0.      0.    ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"+++ Start of data definitions +++\\n\")\n",
    "\n",
    "#\n",
    "# we could do this at the data-frame level, too!\n",
    "#\n",
    "\n",
    "X_all = A[:,0:5]  # X (features) ... is all rows, columns 0, 1, 2, 3\n",
    "y_all = A[:,5]    # y (labels) ... is all rows, column 4 only\n",
    "\n",
    "print(f\"y_all (just the labels/species)   are \\n {y_all}\")\n",
    "print(f\"X_all (just the features) are \\n {X_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scrambled labels/species are \n",
      " [0. 0. 1. ... 0. 1. 0.]\n",
      "The corresponding data rows are \n",
      " [[ 9.  0. 20.  0.  0.]\n",
      " [ 9.  0. 18.  2.  2.]\n",
      " [ 1.  0. 40.  0.  0.]\n",
      " ...\n",
      " [ 9.  0. 28.  0.  0.]\n",
      " [ 9.  5. 27.  0.  3.]\n",
      " [ 9.  0. 26.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# we scramble the data, to remove (potential) dependence on its ordering: \n",
    "# \n",
    "indices = np.random.permutation(len(y_all))  # indices is a permutation-list\n",
    "\n",
    "# we scramble both X and y, necessarily with the same permutation\n",
    "X_labeled = X_all[indices]              # we apply the _same_ permutation to each!\n",
    "y_labeled = y_all[indices]              # again...\n",
    "print(f\"The scrambled labels/species are \\n {y_labeled}\")\n",
    "print(f\"The corresponding data rows are \\n {X_labeled}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 803 rows;  testing with 201 rows\n",
      "\n",
      "Held-out data... (testing data: 201)\n",
      "y_test: [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "X_test (a few rows): [[ 9.  0. 22.  0.  0.]\n",
      " [ 9.  0. 19.  0.  0.]\n",
      " [ 9.  0. 39.  0.  2.]\n",
      " [ 9.  5. 35.  1.  3.]\n",
      " [ 4.  0. 28.  0.  1.]]\n",
      "\n",
      "Data used for modeling... (training data: 803)\n",
      "y_train: [0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0.\n",
      " 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0.]\n",
      "X_train (a few rows): [[ 1.  0. 31.  1.  0.]\n",
      " [ 1.  5. 30.  0.  0.]\n",
      " [ 4.  0. 23.  0.  0.]\n",
      " [ 4.  0. 66.  0.  0.]\n",
      " [ 9.  0. 22.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# We next separate into test data and training data ... \n",
    "#    + We will train on the training data...\n",
    "#    + We will _not_ look at the testing data to build the model\n",
    "#\n",
    "# Then, afterward, we will test on the testing data -- and see how well we do!\n",
    "#\n",
    "\n",
    "#\n",
    "# a common convention:  train on 80%, test on 20%    Let's define the TEST_PERCENT\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"training with {len(y_train)} rows;  testing with {len(y_test)} rows\\n\" )\n",
    "\n",
    "print(f\"Held-out data... (testing data: {len(y_test)})\")\n",
    "print(f\"y_test: {y_test}\")\n",
    "print(f\"X_test (a few rows): {X_test[0:5,:]}\")  # 5 rows\n",
    "print()\n",
    "print(f\"Data used for modeling... (training data: {len(y_train)})\")\n",
    "print(f\"y_train: {y_train}\")\n",
    "print(f\"X_train (a few rows): {X_train[0:5,:]}\")  # 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training with 803 rows;  testing with 201 rows\n",
      "\n",
      "Held-out data... (testing data: 201)\n",
      "y_test: [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "X_test (a few rows): [[ 9.  0. 22.  0.  0.]\n",
      " [ 9.  0. 19.  0.  0.]\n",
      " [ 9.  0. 39.  0.  2.]\n",
      " [ 9.  5. 35.  1.  3.]\n",
      " [ 4.  0. 28.  0.  1.]]\n",
      "\n",
      "Data used for modeling... (training data: 803)\n",
      "y_train: [0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1.\n",
      " 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0.\n",
      " 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0.\n",
      " 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 1.\n",
      " 1. 1. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 1. 1. 1. 0. 1. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0.\n",
      " 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 1. 0.\n",
      " 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 0. 1. 0.\n",
      " 0. 1. 1. 0. 0. 1. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 0.]\n",
      "X_train (a few rows): [[ 1.  0. 31.  1.  0.]\n",
      " [ 1.  5. 30.  0.  0.]\n",
      " [ 4.  0. 23.  0.  0.]\n",
      " [ 4.  0. 66.  0.  0.]\n",
      " [ 9.  0. 22.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "   #\n",
    "# We next separate into test data and training data ... \n",
    "#    + We will train on the training data...\n",
    "#    + We will _not_ look at the testing data to build the model\n",
    "#\n",
    "# Then, afterward, we will test on the testing data -- and see how well we do!\n",
    "#\n",
    "\n",
    "#\n",
    "# a common convention:  train on 80%, test on 20%    Let's define the TEST_PERCENT\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"training with {len(y_train)} rows;  testing with {len(y_test)} rows\\n\" )\n",
    "\n",
    "print(f\"Held-out data... (testing data: {len(y_test)})\")\n",
    "print(f\"y_test: {y_test}\")\n",
    "print(f\"X_test (a few rows): {X_test[0:5,:]}\")  # 5 rows\n",
    "print()\n",
    "print(f\"Data used for modeling... (training data: {len(y_train)})\")\n",
    "print(f\"y_train: {y_train}\")\n",
    "print(f\"X_train (a few rows): {X_train[0:5,:]}\")  # 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  1  cv accuracy:  0.7671\n",
      "k:  2  cv accuracy:  0.7559\n",
      "k:  3  cv accuracy:  0.8007\n",
      "k:  4  cv accuracy:  0.7808\n",
      "k:  5  cv accuracy:  0.7969\n",
      "k:  6  cv accuracy:  0.7895\n",
      "k:  7  cv accuracy:  0.8044\n",
      "k:  8  cv accuracy:  0.7982\n",
      "k:  9  cv accuracy:  0.7907\n",
      "k: 10  cv accuracy:  0.8019\n",
      "k: 11  cv accuracy:  0.8106\n",
      "k: 12  cv accuracy:  0.7957\n",
      "k: 13  cv accuracy:  0.7882\n",
      "k: 14  cv accuracy:  0.7907\n",
      "k: 15  cv accuracy:  0.7907\n",
      "k: 16  cv accuracy:  0.7833\n",
      "k: 17  cv accuracy:  0.7857\n",
      "k: 18  cv accuracy:  0.7845\n",
      "k: 19  cv accuracy:  0.7833\n",
      "k: 20  cv accuracy:  0.7795\n",
      "k: 21  cv accuracy:  0.7808\n",
      "k: 22  cv accuracy:  0.7820\n",
      "k: 23  cv accuracy:  0.7795\n",
      "k: 24  cv accuracy:  0.7808\n",
      "k: 25  cv accuracy:  0.7845\n",
      "k: 26  cv accuracy:  0.7858\n",
      "k: 27  cv accuracy:  0.7883\n",
      "k: 28  cv accuracy:  0.7795\n",
      "k: 29  cv accuracy:  0.7808\n",
      "k: 30  cv accuracy:  0.7783\n",
      "k: 31  cv accuracy:  0.7746\n",
      "k: 32  cv accuracy:  0.7808\n",
      "k: 33  cv accuracy:  0.7795\n",
      "k: 34  cv accuracy:  0.7808\n",
      "k: 35  cv accuracy:  0.7796\n",
      "k: 36  cv accuracy:  0.7796\n",
      "k: 37  cv accuracy:  0.7771\n",
      "k: 38  cv accuracy:  0.7796\n",
      "k: 39  cv accuracy:  0.7758\n",
      "k: 40  cv accuracy:  0.7758\n",
      "k: 41  cv accuracy:  0.7759\n",
      "k: 42  cv accuracy:  0.7783\n",
      "k: 43  cv accuracy:  0.7783\n",
      "k: 44  cv accuracy:  0.7808\n",
      "k: 45  cv accuracy:  0.7846\n",
      "k: 46  cv accuracy:  0.7796\n",
      "k: 47  cv accuracy:  0.7796\n",
      "k: 48  cv accuracy:  0.7733\n",
      "k: 49  cv accuracy:  0.7684\n",
      "k: 50  cv accuracy:  0.7708\n",
      "k: 51  cv accuracy:  0.7733\n",
      "k: 52  cv accuracy:  0.7684\n",
      "k: 53  cv accuracy:  0.7671\n",
      "k: 54  cv accuracy:  0.7671\n",
      "k: 55  cv accuracy:  0.7684\n",
      "k: 56  cv accuracy:  0.7659\n",
      "k: 57  cv accuracy:  0.7684\n",
      "k: 58  cv accuracy:  0.7634\n",
      "k: 59  cv accuracy:  0.7709\n",
      "k: 60  cv accuracy:  0.7721\n",
      "k: 61  cv accuracy:  0.7759\n",
      "k: 62  cv accuracy:  0.7696\n",
      "k: 63  cv accuracy:  0.7759\n",
      "k: 64  cv accuracy:  0.7671\n",
      "k: 65  cv accuracy:  0.7784\n",
      "k: 66  cv accuracy:  0.7709\n",
      "k: 67  cv accuracy:  0.7746\n",
      "k: 68  cv accuracy:  0.7759\n",
      "k: 69  cv accuracy:  0.7821\n",
      "k: 70  cv accuracy:  0.7734\n",
      "k: 71  cv accuracy:  0.7746\n",
      "k: 72  cv accuracy:  0.7684\n",
      "k: 73  cv accuracy:  0.7697\n",
      "k: 74  cv accuracy:  0.7672\n",
      "k: 75  cv accuracy:  0.7709\n",
      "k: 76  cv accuracy:  0.7696\n",
      "k: 77  cv accuracy:  0.7734\n",
      "k: 78  cv accuracy:  0.7709\n",
      "k: 79  cv accuracy:  0.7759\n",
      "k: 80  cv accuracy:  0.7622\n",
      "k: 81  cv accuracy:  0.7634\n",
      "k: 82  cv accuracy:  0.7584\n",
      "k: 83  cv accuracy:  0.7647\n",
      "k: 84  cv accuracy:  0.7584\n",
      "best_k = 11   yields the highest average cv accuracy.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# to do this, we use \"cross validation\"\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#\n",
    "# cross-validation splits the training set into two pieces:\n",
    "#   + model-building and model-validation. We'll use \"build\" and \"validate\"\n",
    "#\n",
    "best_k = 84 # Not correct!\n",
    "best_accuracy = 0.0  # also not correct...\n",
    "\n",
    "# Note that we are cross-validating using only our TEST data!\n",
    "for k in range(1,85):\n",
    "    knn_cv_model = KNeighborsClassifier(n_neighbors=k)   # build knn_model for every k!\n",
    "    cv_scores = cross_val_score( knn_cv_model, X_train, y_train, cv=5 )  # cv=5 means 80/20\n",
    "    # print(cv_scores)  # just to see the five scores... \n",
    "    average_cv_accuracy = cv_scores.mean()  # mean() is numpy's built-in average function \n",
    "    print(f\"k: {k:2d}  cv accuracy: {average_cv_accuracy:7.4f}\")\n",
    "\n",
    "    \n",
    "# assign best value of k to best_k\n",
    "    if average_cv_accuracy > best_accuracy:\n",
    "        best_k = k    # at the moment this is incorrect   TO DO for hw4pr1: fix this...\n",
    "        best_accuracy = average_cv_accuracy\n",
    "# you'll need to use the loop above to find and remember the real best_k\n",
    "\n",
    "print(f\"best_k = {best_k}   yields the highest average cv accuracy.\")  # print the best one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and trained a knn classifier with k = 11\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# +++ This is the \"Model-building and Model-training Cell\"\n",
    "#       \n",
    "# Create a kNN model and train it! \n",
    "#\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k = best_k  # we don't know what k to use, so we guess!  (this will _not_ be a good value)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=k)       # here, k is the \"k\" in kNN\n",
    "\n",
    "# we train the model (it's one line!)\n",
    "knn_model.fit(X_train, y_train)                              # yay!  trained!\n",
    "print(\"Created and trained a knn classifier with k =\", k)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 1. 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "Actual  labels  : [0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1.\n",
      " 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 0.\n",
      " 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0.\n",
      " 1. 0. 0. 1. 1. 0. 0. 1. 0.]\n",
      "\n",
      "Results on test set:  153 correct out of 201 total.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# +++ This cell will \"Model-testing Cell\"\n",
    "#\n",
    "# Now, let's see how well our model does on our \"held-out data\" (the testing data)\n",
    "#\n",
    "\n",
    "# We run our test set:\n",
    "\n",
    "# the function knn_model.predict is the instantiation of our model\n",
    "# it's what runs the k-nearest-neighbors algorithm:\n",
    "predicted_labels = knn_model.predict(X_test)   \n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual  labels  :\", actual_labels)\n",
    "\n",
    "# And, some overall results\n",
    "num_correct = sum(predicted_labels == actual_labels)\n",
    "total = len(actual_labels)\n",
    "print(f\"\\nResults on test set:  {num_correct} correct out of {total} total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row   0 :     perished perished       \n",
      "row   1 :     perished perished       \n",
      "row   2 :     perished perished       \n",
      "row   3 :     perished survived       incorrect\n",
      "row   4 :     perished perished       \n",
      "row   5 :     perished survived       incorrect\n",
      "row   6 :     perished survived       incorrect\n",
      "row   7 :     survived perished       incorrect\n",
      "row   8 :     perished perished       \n",
      "row   9 :     perished perished       \n",
      "row  10 :     perished perished       \n",
      "row  11 :     survived survived       \n",
      "row  12 :     perished survived       incorrect\n",
      "row  13 :     survived survived       \n",
      "row  14 :     perished perished       \n",
      "row  15 :     perished perished       \n",
      "row  16 :     perished perished       \n",
      "row  17 :     perished perished       \n",
      "row  18 :     perished survived       incorrect\n",
      "row  19 :     survived survived       \n",
      "row  20 :     perished perished       \n",
      "row  21 :     perished perished       \n",
      "row  22 :     survived survived       \n",
      "row  23 :     survived survived       \n",
      "row  24 :     perished perished       \n",
      "row  25 :     survived survived       \n",
      "row  26 :     perished perished       \n",
      "row  27 :     perished perished       \n",
      "row  28 :     perished perished       \n",
      "row  29 :     survived perished       incorrect\n",
      "row  30 :     survived perished       incorrect\n",
      "row  31 :     perished perished       \n",
      "row  32 :     perished survived       incorrect\n",
      "row  33 :     perished perished       \n",
      "row  34 :     perished survived       incorrect\n",
      "row  35 :     survived survived       \n",
      "row  36 :     survived perished       incorrect\n",
      "row  37 :     survived survived       \n",
      "row  38 :     perished perished       \n",
      "row  39 :     survived survived       \n",
      "row  40 :     survived survived       \n",
      "row  41 :     perished perished       \n",
      "row  42 :     survived survived       \n",
      "row  43 :     perished perished       \n",
      "row  44 :     survived survived       \n",
      "row  45 :     perished perished       \n",
      "row  46 :     perished perished       \n",
      "row  47 :     survived survived       \n",
      "row  48 :     perished perished       \n",
      "row  49 :     perished perished       \n",
      "row  50 :     perished perished       \n",
      "row  51 :     survived perished       incorrect\n",
      "row  52 :     survived survived       \n",
      "row  53 :     perished perished       \n",
      "row  54 :     survived survived       \n",
      "row  55 :     perished survived       incorrect\n",
      "row  56 :     perished survived       incorrect\n",
      "row  57 :     perished survived       incorrect\n",
      "row  58 :     survived survived       \n",
      "row  59 :     survived survived       \n",
      "row  60 :     perished perished       \n",
      "row  61 :     perished perished       \n",
      "row  62 :     perished perished       \n",
      "row  63 :     perished perished       \n",
      "row  64 :     perished survived       incorrect\n",
      "row  65 :     perished perished       \n",
      "row  66 :     perished perished       \n",
      "row  67 :     perished perished       \n",
      "row  68 :     survived survived       \n",
      "row  69 :     perished perished       \n",
      "row  70 :     perished survived       incorrect\n",
      "row  71 :     survived survived       \n",
      "row  72 :     perished survived       incorrect\n",
      "row  73 :     perished perished       \n",
      "row  74 :     perished survived       incorrect\n",
      "row  75 :     perished perished       \n",
      "row  76 :     perished perished       \n",
      "row  77 :     perished survived       incorrect\n",
      "row  78 :     survived survived       \n",
      "row  79 :     perished survived       incorrect\n",
      "row  80 :     survived survived       \n",
      "row  81 :     perished perished       \n",
      "row  82 :     survived survived       \n",
      "row  83 :     survived survived       \n",
      "row  84 :     perished perished       \n",
      "row  85 :     perished perished       \n",
      "row  86 :     perished perished       \n",
      "row  87 :     survived perished       incorrect\n",
      "row  88 :     survived survived       \n",
      "row  89 :     perished survived       incorrect\n",
      "row  90 :     perished perished       \n",
      "row  91 :     survived perished       incorrect\n",
      "row  92 :     perished survived       incorrect\n",
      "row  93 :     perished perished       \n",
      "row  94 :     survived survived       \n",
      "row  95 :     perished perished       \n",
      "row  96 :     perished perished       \n",
      "row  97 :     perished perished       \n",
      "row  98 :     survived survived       \n",
      "row  99 :     survived survived       \n",
      "row 100 :     perished survived       incorrect\n",
      "row 101 :     perished perished       \n",
      "row 102 :     survived survived       \n",
      "row 103 :     perished perished       \n",
      "row 104 :     perished survived       incorrect\n",
      "row 105 :     survived survived       \n",
      "row 106 :     perished survived       incorrect\n",
      "row 107 :     perished survived       incorrect\n",
      "row 108 :     perished survived       incorrect\n",
      "row 109 :     perished perished       \n",
      "row 110 :     perished perished       \n",
      "row 111 :     perished perished       \n",
      "row 112 :     survived perished       incorrect\n",
      "row 113 :     perished perished       \n",
      "row 114 :     perished perished       \n",
      "row 115 :     perished survived       incorrect\n",
      "row 116 :     perished perished       \n",
      "row 117 :     perished survived       incorrect\n",
      "row 118 :     survived survived       \n",
      "row 119 :     perished perished       \n",
      "row 120 :     survived survived       \n",
      "row 121 :     survived survived       \n",
      "row 122 :     survived survived       \n",
      "row 123 :     perished survived       incorrect\n",
      "row 124 :     survived survived       \n",
      "row 125 :     survived survived       \n",
      "row 126 :     survived perished       incorrect\n",
      "row 127 :     perished perished       \n",
      "row 128 :     survived survived       \n",
      "row 129 :     perished survived       incorrect\n",
      "row 130 :     perished perished       \n",
      "row 131 :     perished perished       \n",
      "row 132 :     perished perished       \n",
      "row 133 :     perished survived       incorrect\n",
      "row 134 :     perished perished       \n",
      "row 135 :     perished perished       \n",
      "row 136 :     perished perished       \n",
      "row 137 :     perished perished       \n",
      "row 138 :     perished perished       \n",
      "row 139 :     survived survived       \n",
      "row 140 :     perished survived       incorrect\n",
      "row 141 :     survived survived       \n",
      "row 142 :     survived survived       \n",
      "row 143 :     survived perished       incorrect\n",
      "row 144 :     perished perished       \n",
      "row 145 :     perished perished       \n",
      "row 146 :     perished survived       incorrect\n",
      "row 147 :     survived survived       \n",
      "row 148 :     perished perished       \n",
      "row 149 :     perished perished       \n",
      "row 150 :     survived survived       \n",
      "row 151 :     perished perished       \n",
      "row 152 :     perished perished       \n",
      "row 153 :     perished survived       incorrect\n",
      "row 154 :     perished survived       incorrect\n",
      "row 155 :     perished survived       incorrect\n",
      "row 156 :     perished perished       \n",
      "row 157 :     perished perished       \n",
      "row 158 :     survived survived       \n",
      "row 159 :     survived survived       \n",
      "row 160 :     survived survived       \n",
      "row 161 :     perished perished       \n",
      "row 162 :     perished perished       \n",
      "row 163 :     perished perished       \n",
      "row 164 :     perished perished       \n",
      "row 165 :     perished perished       \n",
      "row 166 :     perished perished       \n",
      "row 167 :     perished perished       \n",
      "row 168 :     survived survived       \n",
      "row 169 :     perished perished       \n",
      "row 170 :     survived perished       incorrect\n",
      "row 171 :     perished perished       \n",
      "row 172 :     perished perished       \n",
      "row 173 :     survived perished       incorrect\n",
      "row 174 :     survived survived       \n",
      "row 175 :     perished perished       \n",
      "row 176 :     survived survived       \n",
      "row 177 :     perished perished       \n",
      "row 178 :     survived survived       \n",
      "row 179 :     survived survived       \n",
      "row 180 :     perished perished       \n",
      "row 181 :     survived survived       \n",
      "row 182 :     perished perished       \n",
      "row 183 :     perished perished       \n",
      "row 184 :     survived survived       \n",
      "row 185 :     survived survived       \n",
      "row 186 :     perished survived       incorrect\n",
      "row 187 :     survived survived       \n",
      "row 188 :     perished perished       \n",
      "row 189 :     perished perished       \n",
      "row 190 :     perished survived       incorrect\n",
      "row 191 :     perished perished       \n",
      "row 192 :     perished survived       incorrect\n",
      "row 193 :     perished perished       \n",
      "row 194 :     perished perished       \n",
      "row 195 :     survived survived       \n",
      "row 196 :     survived survived       \n",
      "row 197 :     perished perished       \n",
      "row 198 :     perished perished       \n",
      "row 199 :     survived survived       \n",
      "row 200 :     perished perished       \n",
      "\n",
      "Correct: 153 out of 201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_labels(predicted_labels, actual_labels):\n",
    "    \"\"\" a more neatly formatted comparison \"\"\"\n",
    "    NUM_LABELS = len(predicted_labels)\n",
    "    num_correct = 0\n",
    "    \n",
    "    for i in range(NUM_LABELS):\n",
    "        p = int(round(predicted_labels[i]))         # round protects from fp error \n",
    "        a = int(round(actual_labels[i]))\n",
    "        result = \"incorrect\"\n",
    "        if p == a:  # if they match,\n",
    "            result = \"\"       # no longer incorrect\n",
    "            num_correct += 1  # and we count a match!\n",
    "\n",
    "        print(f\"row {i:>3d} : {OUTCOME[p]:>12s} {OUTCOME[a]:<12s}   {result}\")   \n",
    "\n",
    "    print()\n",
    "    print(\"Correct:\", num_correct, \"out of\", NUM_LABELS)\n",
    "    return num_correct\n",
    "\n",
    "# let's try it out!\n",
    "compare_labels(predicted_labels,actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created + trained a 'final' knn classifier, with a (best) k of 11\n"
     ]
    }
   ],
   "source": [
    "# Ok!  We have tuned knn to use the \"best\" value of k...\n",
    "#\n",
    "# And, we should now use ALL available data to train our final predictive model:\n",
    "#\n",
    "\n",
    "knn_model_final = KNeighborsClassifier(n_neighbors=best_k)   # here, we use the best_k\n",
    "knn_model_final.fit(X_all, y_all)                              # here we use ALL the data!\n",
    "print(f\"Created + trained a 'final' knn classifier, with a (best) k of {best_k}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I predict survived from the features (1, 5, 20, 0, 2)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# final predictive model (k-nearest-neighbor), with tuned k + ALL data incorporated\n",
    "#\n",
    "\n",
    "def predictive_model( Features, Model ):\n",
    "    \"\"\" input: a list of five features \n",
    "            [ pclass' (ticket class, 1-3), \n",
    "            'sex', (male (0), female (5))\n",
    "            'age',\n",
    "            'sibsp' (# of siblings or spouses)\n",
    "            'parch', (# of children or parents)]\n",
    "        output: the predicted outcome of individuals, from\n",
    "                  survived (1), perished (0)\n",
    "    \"\"\"\n",
    "    # put features into a list!\n",
    "    our_features = np.asarray([Features])                 # extra brackets needed\n",
    "\n",
    "    # The model's prediction!\n",
    "    predicted_outcome = Model.predict(our_features)\n",
    "    \n",
    "    # a bit awkward\n",
    "    predicted_outcome = int(round(predicted_outcome[0]))  # unpack one element\n",
    "    return predicted_outcome\n",
    "\n",
    "    \n",
    "#\n",
    "# Try it!\n",
    "# \n",
    "Features = eval(input(\"Enter new Features: \"))\n",
    "\n",
    "# Features = [6.7,3.3,5.7,0.1]  # [5.8,2.7,4.1,1.0] [4.6,3.6,3.0,2.2] [6.7,3.3,5.7,2.1]\n",
    "\n",
    "predicted_outcome = predictive_model( Features, knn_model_final )  # pass in the model, too!\n",
    "name = OUTCOME[predicted_outcome]\n",
    "print(f\"I predict {name} from the features {Features}\")\n",
    "\n",
    "# LoF = [\n",
    "# [4.8, 3.1, 1.6, 0.2 ],\n",
    "# [5.7, 2.9, 4.2, 1.3 ],\n",
    "# [5.8, 2.7, 5.1, 1.9 ],\n",
    "# [5.2, 4.1, 1.5, 0.1 ],\n",
    "# [5.4, 3.4, 1.5, 0.4 ],\n",
    "# [5.1, 2.5, 3.0, 1.1 ],\n",
    "# [6.2, 2.9, 4.3, 1.3 ],\n",
    "# [6.3, 3.3, 6.0, 2.5 ],\n",
    "# [5.7, 2.8, 4.1, 1.3 ],\n",
    "#   ]\n",
    "\n",
    "# run on each one:\n",
    "# for Features in LoF:\n",
    "    # predicted_outcome = predictive_model( Features, knn_model_final )  # pass in the model, too!\n",
    "    # name = OUTCOME[predicted_outcome]\n",
    "    # print(f\"I predict {name} from the features {Features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thoughts on Titanic\n",
    "- best cross validation accuracy: 0.8106 when k = 11\n",
    "- which feature is most important\n",
    "    - Weighting the class was most important. Before with no weighting, the accuracy was 128/200 correct predictions. After weighting the 3rd and 2nd classes progressively more heavily, the accuracy was 151/200. Weighting sex (parents with children) also helped with the accuracy.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
